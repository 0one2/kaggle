{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2012, 4) (4700, 3) (7656334, 9)\n",
      "(6712, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "train = pd.read_csv(\"../input/facebook-recruiting-iv-human-or-bot/train.csv\")\n",
    "test = pd.read_csv(\"../input/facebook-recruiting-iv-human-or-bot/test.csv\")\n",
    "bids = pd.read_csv(\"../input/facebook-recruiting-iv-human-or-bot/bids.csv\")\n",
    "train.drop(1122,inplace=True)\n",
    "print(train.shape, test.shape, bids.shape)\n",
    "train.head()\n",
    "\n",
    "alldata = pd.concat([train, test], sort=False)\n",
    "print(alldata.shape)\n",
    "alldata.head()\n",
    "\n",
    "alldata[\"payment_account\"] = alldata.payment_account.apply(lambda x: str(x)[:5])\n",
    "alldata[\"address\"] = alldata.address.apply(lambda x: str(x)[:5])\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "alldata[\"payment_account\"] = le.fit_transform(alldata[\"payment_account\"]).astype(np.int16)\n",
    "alldata[\"address\"] = le.fit_transform(alldata[\"address\"]).astype(np.int16)\n",
    "alldata[\"outcome\"] = alldata[\"outcome\"].astype(np.float16)\n",
    "import gc; gc.collect()\n",
    "\n",
    "bids.drop([\"bid_id\"], 1, inplace=True)\n",
    "\n",
    "work = bids.sort_values(\"bidder_id\")\n",
    "timework = work[[\"bidder_id\", \"time\"]]\n",
    "auc_count_nunique = work.groupby(\"bidder_id\")[\"auction\"].agg([\"count\", \"nunique\"]).reset_index()\n",
    "alldata = alldata.merge(auc_count_nunique, how = \"left\", on = \"bidder_id\")\n",
    "alldata[\"nunique_div_count\"] = alldata[\"nunique\"]/alldata[\"count\"]\n",
    "\n",
    "merchan = pd.DataFrame(work.groupby(\"bidder_id\")[\"merchandise\"].apply(lambda x: x.mode())).reset_index()\n",
    "alldata = alldata.merge(merchan, how = \"left\", on=\"bidder_id\")\n",
    "alldata.drop(\"level_1\",1,inplace=True)\n",
    "alldata[\"merchandise\"] = le.fit_transform(alldata[\"merchandise\"].astype(\"str\")).astype(np.int16)\n",
    "\n",
    "dev_count_nunique = work.groupby(\"bidder_id\")[\"device\"].agg([\"count\", \"nunique\"]).reset_index()\n",
    "alldata = alldata.merge(dev_count_nunique, how = \"left\", on = \"bidder_id\")\n",
    "alldata[\"dev_nunique_div_count\"] = alldata[\"nunique_y\"]/alldata[\"count_y\"]\n",
    "alldata.drop(\"count_y\",1,inplace=True)\n",
    "\n",
    "alldata = alldata.merge(pd.DataFrame(work.groupby(\"bidder_id\")[\"country\"].nunique()).reset_index(), how=\"left\", on=\"bidder_id\")\n",
    "\n",
    "ip_url_nunique = work.groupby(\"bidder_id\")[\"ip\", \"url\"].nunique().reset_index()\n",
    "alldata = alldata.merge(ip_url_nunique, how = \"left\", on = \"bidder_id\")\n",
    "alldata[\"ip_nuni_div_count\"] = alldata[\"ip\"]/alldata[\"count_x\"]\n",
    "alldata[\"url_nuni_div_count\"] = alldata[\"url\"]/alldata[\"count_x\"]\n",
    "alldata = alldata.merge(pd.DataFrame(timework.groupby(\"bidder_id\")[\"time\"].apply(lambda x:(x.max() - x.min()))).reset_index(), how = \"left\", on = \"bidder_id\")\n",
    "alldata[\"time_div_count\"] = alldata[\"time\"] / alldata[\"count_x\"]\n",
    "\n",
    "\n",
    "    \n",
    "k = pd.read_csv(\"../input/i-m-not-robot/timediff.csv\")\n",
    "alldata = alldata.merge(k, how = \"left\", on = \"bidder_id\")\n",
    "\n",
    "train = alldata.iloc[:len(train), :]\n",
    "test = alldata.iloc[len(train):, :]\n",
    "\n",
    "y = train[\"outcome\"]\n",
    "train.drop([\"outcome\", \"bidder_id\"],1,inplace=True)\n",
    "test.drop([\"outcome\", \"bidder_id\"],1,inplace=True)\n",
    "train.fillna(-1, inplace=True)\n",
    "test.fillna(-1, inplace=True)\n",
    "train.head()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 300, random_state = 42, n_jobs=-1, max_depth = 9)\n",
    "rf.fit(train, y)\n",
    "preds = rf.predict_proba(test)\n",
    "sub = pd.read_csv(\"../input/facebook-recruiting-iv-human-or-bot/sampleSubmission.csv\")\n",
    "sub.prediction = preds[:,1]\n",
    "sub.to_csv(\"ha.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
