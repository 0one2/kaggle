{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "path = \"../input/train/\"\n",
    "train_set = pd.read_csv('../input/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_label = np.array(train_set['invasive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "for i in range(len(train_set)):\n",
    "    train_files.append(path + str(int(train_set.iloc[i][0])) +'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/train/1.jpg',\n",
       " '../input/train/2.jpg',\n",
       " '../input/train/3.jpg',\n",
       " '../input/train/4.jpg',\n",
       " '../input/train/5.jpg',\n",
       " '../input/train/6.jpg',\n",
       " '../input/train/7.jpg',\n",
       " '../input/train/8.jpg',\n",
       " '../input/train/9.jpg',\n",
       " '../input/train/10.jpg',\n",
       " '../input/train/11.jpg',\n",
       " '../input/train/12.jpg',\n",
       " '../input/train/13.jpg',\n",
       " '../input/train/14.jpg',\n",
       " '../input/train/15.jpg',\n",
       " '../input/train/16.jpg',\n",
       " '../input/train/17.jpg',\n",
       " '../input/train/18.jpg',\n",
       " '../input/train/19.jpg',\n",
       " '../input/train/20.jpg',\n",
       " '../input/train/21.jpg',\n",
       " '../input/train/22.jpg',\n",
       " '../input/train/23.jpg',\n",
       " '../input/train/24.jpg',\n",
       " '../input/train/25.jpg',\n",
       " '../input/train/26.jpg',\n",
       " '../input/train/27.jpg',\n",
       " '../input/train/28.jpg',\n",
       " '../input/train/29.jpg',\n",
       " '../input/train/30.jpg',\n",
       " '../input/train/31.jpg',\n",
       " '../input/train/32.jpg',\n",
       " '../input/train/33.jpg',\n",
       " '../input/train/34.jpg',\n",
       " '../input/train/35.jpg',\n",
       " '../input/train/36.jpg',\n",
       " '../input/train/37.jpg',\n",
       " '../input/train/38.jpg',\n",
       " '../input/train/39.jpg',\n",
       " '../input/train/40.jpg',\n",
       " '../input/train/41.jpg',\n",
       " '../input/train/42.jpg',\n",
       " '../input/train/43.jpg',\n",
       " '../input/train/44.jpg',\n",
       " '../input/train/45.jpg',\n",
       " '../input/train/46.jpg',\n",
       " '../input/train/47.jpg',\n",
       " '../input/train/48.jpg',\n",
       " '../input/train/49.jpg',\n",
       " '../input/train/50.jpg',\n",
       " '../input/train/51.jpg',\n",
       " '../input/train/52.jpg',\n",
       " '../input/train/53.jpg',\n",
       " '../input/train/54.jpg',\n",
       " '../input/train/55.jpg',\n",
       " '../input/train/56.jpg',\n",
       " '../input/train/57.jpg',\n",
       " '../input/train/58.jpg',\n",
       " '../input/train/59.jpg',\n",
       " '../input/train/60.jpg',\n",
       " '../input/train/61.jpg',\n",
       " '../input/train/62.jpg',\n",
       " '../input/train/63.jpg',\n",
       " '../input/train/64.jpg',\n",
       " '../input/train/65.jpg',\n",
       " '../input/train/66.jpg',\n",
       " '../input/train/67.jpg',\n",
       " '../input/train/68.jpg',\n",
       " '../input/train/69.jpg',\n",
       " '../input/train/70.jpg',\n",
       " '../input/train/71.jpg',\n",
       " '../input/train/72.jpg',\n",
       " '../input/train/73.jpg',\n",
       " '../input/train/74.jpg',\n",
       " '../input/train/75.jpg',\n",
       " '../input/train/76.jpg',\n",
       " '../input/train/77.jpg',\n",
       " '../input/train/78.jpg',\n",
       " '../input/train/79.jpg',\n",
       " '../input/train/80.jpg',\n",
       " '../input/train/81.jpg',\n",
       " '../input/train/82.jpg',\n",
       " '../input/train/83.jpg',\n",
       " '../input/train/84.jpg',\n",
       " '../input/train/85.jpg',\n",
       " '../input/train/86.jpg',\n",
       " '../input/train/87.jpg',\n",
       " '../input/train/88.jpg',\n",
       " '../input/train/89.jpg',\n",
       " '../input/train/90.jpg',\n",
       " '../input/train/91.jpg',\n",
       " '../input/train/92.jpg',\n",
       " '../input/train/93.jpg',\n",
       " '../input/train/94.jpg',\n",
       " '../input/train/95.jpg',\n",
       " '../input/train/96.jpg',\n",
       " '../input/train/97.jpg',\n",
       " '../input/train/98.jpg',\n",
       " '../input/train/99.jpg',\n",
       " '../input/train/100.jpg',\n",
       " '../input/train/101.jpg',\n",
       " '../input/train/102.jpg',\n",
       " '../input/train/103.jpg',\n",
       " '../input/train/104.jpg',\n",
       " '../input/train/105.jpg',\n",
       " '../input/train/106.jpg',\n",
       " '../input/train/107.jpg',\n",
       " '../input/train/108.jpg',\n",
       " '../input/train/109.jpg',\n",
       " '../input/train/110.jpg',\n",
       " '../input/train/111.jpg',\n",
       " '../input/train/112.jpg',\n",
       " '../input/train/113.jpg',\n",
       " '../input/train/114.jpg',\n",
       " '../input/train/115.jpg',\n",
       " '../input/train/116.jpg',\n",
       " '../input/train/117.jpg',\n",
       " '../input/train/118.jpg',\n",
       " '../input/train/119.jpg',\n",
       " '../input/train/120.jpg',\n",
       " '../input/train/121.jpg',\n",
       " '../input/train/122.jpg',\n",
       " '../input/train/123.jpg',\n",
       " '../input/train/124.jpg',\n",
       " '../input/train/125.jpg',\n",
       " '../input/train/126.jpg',\n",
       " '../input/train/127.jpg',\n",
       " '../input/train/128.jpg',\n",
       " '../input/train/129.jpg',\n",
       " '../input/train/130.jpg',\n",
       " '../input/train/131.jpg',\n",
       " '../input/train/132.jpg',\n",
       " '../input/train/133.jpg',\n",
       " '../input/train/134.jpg',\n",
       " '../input/train/135.jpg',\n",
       " '../input/train/136.jpg',\n",
       " '../input/train/137.jpg',\n",
       " '../input/train/138.jpg',\n",
       " '../input/train/139.jpg',\n",
       " '../input/train/140.jpg',\n",
       " '../input/train/141.jpg',\n",
       " '../input/train/142.jpg',\n",
       " '../input/train/143.jpg',\n",
       " '../input/train/144.jpg',\n",
       " '../input/train/145.jpg',\n",
       " '../input/train/146.jpg',\n",
       " '../input/train/147.jpg',\n",
       " '../input/train/148.jpg',\n",
       " '../input/train/149.jpg',\n",
       " '../input/train/150.jpg',\n",
       " '../input/train/151.jpg',\n",
       " '../input/train/152.jpg',\n",
       " '../input/train/153.jpg',\n",
       " '../input/train/154.jpg',\n",
       " '../input/train/155.jpg',\n",
       " '../input/train/156.jpg',\n",
       " '../input/train/157.jpg',\n",
       " '../input/train/158.jpg',\n",
       " '../input/train/159.jpg',\n",
       " '../input/train/160.jpg',\n",
       " '../input/train/161.jpg',\n",
       " '../input/train/162.jpg',\n",
       " '../input/train/163.jpg',\n",
       " '../input/train/164.jpg',\n",
       " '../input/train/165.jpg',\n",
       " '../input/train/166.jpg',\n",
       " '../input/train/167.jpg',\n",
       " '../input/train/168.jpg',\n",
       " '../input/train/169.jpg',\n",
       " '../input/train/170.jpg',\n",
       " '../input/train/171.jpg',\n",
       " '../input/train/172.jpg',\n",
       " '../input/train/173.jpg',\n",
       " '../input/train/174.jpg',\n",
       " '../input/train/175.jpg',\n",
       " '../input/train/176.jpg',\n",
       " '../input/train/177.jpg',\n",
       " '../input/train/178.jpg',\n",
       " '../input/train/179.jpg',\n",
       " '../input/train/180.jpg',\n",
       " '../input/train/181.jpg',\n",
       " '../input/train/182.jpg',\n",
       " '../input/train/183.jpg',\n",
       " '../input/train/184.jpg',\n",
       " '../input/train/185.jpg',\n",
       " '../input/train/186.jpg',\n",
       " '../input/train/187.jpg',\n",
       " '../input/train/188.jpg',\n",
       " '../input/train/189.jpg',\n",
       " '../input/train/190.jpg',\n",
       " '../input/train/191.jpg',\n",
       " '../input/train/192.jpg',\n",
       " '../input/train/193.jpg',\n",
       " '../input/train/194.jpg',\n",
       " '../input/train/195.jpg',\n",
       " '../input/train/196.jpg',\n",
       " '../input/train/197.jpg',\n",
       " '../input/train/198.jpg',\n",
       " '../input/train/199.jpg',\n",
       " '../input/train/200.jpg',\n",
       " '../input/train/201.jpg',\n",
       " '../input/train/202.jpg',\n",
       " '../input/train/203.jpg',\n",
       " '../input/train/204.jpg',\n",
       " '../input/train/205.jpg',\n",
       " '../input/train/206.jpg',\n",
       " '../input/train/207.jpg',\n",
       " '../input/train/208.jpg',\n",
       " '../input/train/209.jpg',\n",
       " '../input/train/210.jpg',\n",
       " '../input/train/211.jpg',\n",
       " '../input/train/212.jpg',\n",
       " '../input/train/213.jpg',\n",
       " '../input/train/214.jpg',\n",
       " '../input/train/215.jpg',\n",
       " '../input/train/216.jpg',\n",
       " '../input/train/217.jpg',\n",
       " '../input/train/218.jpg',\n",
       " '../input/train/219.jpg',\n",
       " '../input/train/220.jpg',\n",
       " '../input/train/221.jpg',\n",
       " '../input/train/222.jpg',\n",
       " '../input/train/223.jpg',\n",
       " '../input/train/224.jpg',\n",
       " '../input/train/225.jpg',\n",
       " '../input/train/226.jpg',\n",
       " '../input/train/227.jpg',\n",
       " '../input/train/228.jpg',\n",
       " '../input/train/229.jpg',\n",
       " '../input/train/230.jpg',\n",
       " '../input/train/231.jpg',\n",
       " '../input/train/232.jpg',\n",
       " '../input/train/233.jpg',\n",
       " '../input/train/234.jpg',\n",
       " '../input/train/235.jpg',\n",
       " '../input/train/236.jpg',\n",
       " '../input/train/237.jpg',\n",
       " '../input/train/238.jpg',\n",
       " '../input/train/239.jpg',\n",
       " '../input/train/240.jpg',\n",
       " '../input/train/241.jpg',\n",
       " '../input/train/242.jpg',\n",
       " '../input/train/243.jpg',\n",
       " '../input/train/244.jpg',\n",
       " '../input/train/245.jpg',\n",
       " '../input/train/246.jpg',\n",
       " '../input/train/247.jpg',\n",
       " '../input/train/248.jpg',\n",
       " '../input/train/249.jpg',\n",
       " '../input/train/250.jpg',\n",
       " '../input/train/251.jpg',\n",
       " '../input/train/252.jpg',\n",
       " '../input/train/253.jpg',\n",
       " '../input/train/254.jpg',\n",
       " '../input/train/255.jpg',\n",
       " '../input/train/256.jpg',\n",
       " '../input/train/257.jpg',\n",
       " '../input/train/258.jpg',\n",
       " '../input/train/259.jpg',\n",
       " '../input/train/260.jpg',\n",
       " '../input/train/261.jpg',\n",
       " '../input/train/262.jpg',\n",
       " '../input/train/263.jpg',\n",
       " '../input/train/264.jpg',\n",
       " '../input/train/265.jpg',\n",
       " '../input/train/266.jpg',\n",
       " '../input/train/267.jpg',\n",
       " '../input/train/268.jpg',\n",
       " '../input/train/269.jpg',\n",
       " '../input/train/270.jpg',\n",
       " '../input/train/271.jpg',\n",
       " '../input/train/272.jpg',\n",
       " '../input/train/273.jpg',\n",
       " '../input/train/274.jpg',\n",
       " '../input/train/275.jpg',\n",
       " '../input/train/276.jpg',\n",
       " '../input/train/277.jpg',\n",
       " '../input/train/278.jpg',\n",
       " '../input/train/279.jpg',\n",
       " '../input/train/280.jpg',\n",
       " '../input/train/281.jpg',\n",
       " '../input/train/282.jpg',\n",
       " '../input/train/283.jpg',\n",
       " '../input/train/284.jpg',\n",
       " '../input/train/285.jpg',\n",
       " '../input/train/286.jpg',\n",
       " '../input/train/287.jpg',\n",
       " '../input/train/288.jpg',\n",
       " '../input/train/289.jpg',\n",
       " '../input/train/290.jpg',\n",
       " '../input/train/291.jpg',\n",
       " '../input/train/292.jpg',\n",
       " '../input/train/293.jpg',\n",
       " '../input/train/294.jpg',\n",
       " '../input/train/295.jpg',\n",
       " '../input/train/296.jpg',\n",
       " '../input/train/297.jpg',\n",
       " '../input/train/298.jpg',\n",
       " '../input/train/299.jpg',\n",
       " '../input/train/300.jpg',\n",
       " '../input/train/301.jpg',\n",
       " '../input/train/302.jpg',\n",
       " '../input/train/303.jpg',\n",
       " '../input/train/304.jpg',\n",
       " '../input/train/305.jpg',\n",
       " '../input/train/306.jpg',\n",
       " '../input/train/307.jpg',\n",
       " '../input/train/308.jpg',\n",
       " '../input/train/309.jpg',\n",
       " '../input/train/310.jpg',\n",
       " '../input/train/311.jpg',\n",
       " '../input/train/312.jpg',\n",
       " '../input/train/313.jpg',\n",
       " '../input/train/314.jpg',\n",
       " '../input/train/315.jpg',\n",
       " '../input/train/316.jpg',\n",
       " '../input/train/317.jpg',\n",
       " '../input/train/318.jpg',\n",
       " '../input/train/319.jpg',\n",
       " '../input/train/320.jpg',\n",
       " '../input/train/321.jpg',\n",
       " '../input/train/322.jpg',\n",
       " '../input/train/323.jpg',\n",
       " '../input/train/324.jpg',\n",
       " '../input/train/325.jpg',\n",
       " '../input/train/326.jpg',\n",
       " '../input/train/327.jpg',\n",
       " '../input/train/328.jpg',\n",
       " '../input/train/329.jpg',\n",
       " '../input/train/330.jpg',\n",
       " '../input/train/331.jpg',\n",
       " '../input/train/332.jpg',\n",
       " '../input/train/333.jpg',\n",
       " '../input/train/334.jpg',\n",
       " '../input/train/335.jpg',\n",
       " '../input/train/336.jpg',\n",
       " '../input/train/337.jpg',\n",
       " '../input/train/338.jpg',\n",
       " '../input/train/339.jpg',\n",
       " '../input/train/340.jpg',\n",
       " '../input/train/341.jpg',\n",
       " '../input/train/342.jpg',\n",
       " '../input/train/343.jpg',\n",
       " '../input/train/344.jpg',\n",
       " '../input/train/345.jpg',\n",
       " '../input/train/346.jpg',\n",
       " '../input/train/347.jpg',\n",
       " '../input/train/348.jpg',\n",
       " '../input/train/349.jpg',\n",
       " '../input/train/350.jpg',\n",
       " '../input/train/351.jpg',\n",
       " '../input/train/352.jpg',\n",
       " '../input/train/353.jpg',\n",
       " '../input/train/354.jpg',\n",
       " '../input/train/355.jpg',\n",
       " '../input/train/356.jpg',\n",
       " '../input/train/357.jpg',\n",
       " '../input/train/358.jpg',\n",
       " '../input/train/359.jpg',\n",
       " '../input/train/360.jpg',\n",
       " '../input/train/361.jpg',\n",
       " '../input/train/362.jpg',\n",
       " '../input/train/363.jpg',\n",
       " '../input/train/364.jpg',\n",
       " '../input/train/365.jpg',\n",
       " '../input/train/366.jpg',\n",
       " '../input/train/367.jpg',\n",
       " '../input/train/368.jpg',\n",
       " '../input/train/369.jpg',\n",
       " '../input/train/370.jpg',\n",
       " '../input/train/371.jpg',\n",
       " '../input/train/372.jpg',\n",
       " '../input/train/373.jpg',\n",
       " '../input/train/374.jpg',\n",
       " '../input/train/375.jpg',\n",
       " '../input/train/376.jpg',\n",
       " '../input/train/377.jpg',\n",
       " '../input/train/378.jpg',\n",
       " '../input/train/379.jpg',\n",
       " '../input/train/380.jpg',\n",
       " '../input/train/381.jpg',\n",
       " '../input/train/382.jpg',\n",
       " '../input/train/383.jpg',\n",
       " '../input/train/384.jpg',\n",
       " '../input/train/385.jpg',\n",
       " '../input/train/386.jpg',\n",
       " '../input/train/387.jpg',\n",
       " '../input/train/388.jpg',\n",
       " '../input/train/389.jpg',\n",
       " '../input/train/390.jpg',\n",
       " '../input/train/391.jpg',\n",
       " '../input/train/392.jpg',\n",
       " '../input/train/393.jpg',\n",
       " '../input/train/394.jpg',\n",
       " '../input/train/395.jpg',\n",
       " '../input/train/396.jpg',\n",
       " '../input/train/397.jpg',\n",
       " '../input/train/398.jpg',\n",
       " '../input/train/399.jpg',\n",
       " '../input/train/400.jpg',\n",
       " '../input/train/401.jpg',\n",
       " '../input/train/402.jpg',\n",
       " '../input/train/403.jpg',\n",
       " '../input/train/404.jpg',\n",
       " '../input/train/405.jpg',\n",
       " '../input/train/406.jpg',\n",
       " '../input/train/407.jpg',\n",
       " '../input/train/408.jpg',\n",
       " '../input/train/409.jpg',\n",
       " '../input/train/410.jpg',\n",
       " '../input/train/411.jpg',\n",
       " '../input/train/412.jpg',\n",
       " '../input/train/413.jpg',\n",
       " '../input/train/414.jpg',\n",
       " '../input/train/415.jpg',\n",
       " '../input/train/416.jpg',\n",
       " '../input/train/417.jpg',\n",
       " '../input/train/418.jpg',\n",
       " '../input/train/419.jpg',\n",
       " '../input/train/420.jpg',\n",
       " '../input/train/421.jpg',\n",
       " '../input/train/422.jpg',\n",
       " '../input/train/423.jpg',\n",
       " '../input/train/424.jpg',\n",
       " '../input/train/425.jpg',\n",
       " '../input/train/426.jpg',\n",
       " '../input/train/427.jpg',\n",
       " '../input/train/428.jpg',\n",
       " '../input/train/429.jpg',\n",
       " '../input/train/430.jpg',\n",
       " '../input/train/431.jpg',\n",
       " '../input/train/432.jpg',\n",
       " '../input/train/433.jpg',\n",
       " '../input/train/434.jpg',\n",
       " '../input/train/435.jpg',\n",
       " '../input/train/436.jpg',\n",
       " '../input/train/437.jpg',\n",
       " '../input/train/438.jpg',\n",
       " '../input/train/439.jpg',\n",
       " '../input/train/440.jpg',\n",
       " '../input/train/441.jpg',\n",
       " '../input/train/442.jpg',\n",
       " '../input/train/443.jpg',\n",
       " '../input/train/444.jpg',\n",
       " '../input/train/445.jpg',\n",
       " '../input/train/446.jpg',\n",
       " '../input/train/447.jpg',\n",
       " '../input/train/448.jpg',\n",
       " '../input/train/449.jpg',\n",
       " '../input/train/450.jpg',\n",
       " '../input/train/451.jpg',\n",
       " '../input/train/452.jpg',\n",
       " '../input/train/453.jpg',\n",
       " '../input/train/454.jpg',\n",
       " '../input/train/455.jpg',\n",
       " '../input/train/456.jpg',\n",
       " '../input/train/457.jpg',\n",
       " '../input/train/458.jpg',\n",
       " '../input/train/459.jpg',\n",
       " '../input/train/460.jpg',\n",
       " '../input/train/461.jpg',\n",
       " '../input/train/462.jpg',\n",
       " '../input/train/463.jpg',\n",
       " '../input/train/464.jpg',\n",
       " '../input/train/465.jpg',\n",
       " '../input/train/466.jpg',\n",
       " '../input/train/467.jpg',\n",
       " '../input/train/468.jpg',\n",
       " '../input/train/469.jpg',\n",
       " '../input/train/470.jpg',\n",
       " '../input/train/471.jpg',\n",
       " '../input/train/472.jpg',\n",
       " '../input/train/473.jpg',\n",
       " '../input/train/474.jpg',\n",
       " '../input/train/475.jpg',\n",
       " '../input/train/476.jpg',\n",
       " '../input/train/477.jpg',\n",
       " '../input/train/478.jpg',\n",
       " '../input/train/479.jpg',\n",
       " '../input/train/480.jpg',\n",
       " '../input/train/481.jpg',\n",
       " '../input/train/482.jpg',\n",
       " '../input/train/483.jpg',\n",
       " '../input/train/484.jpg',\n",
       " '../input/train/485.jpg',\n",
       " '../input/train/486.jpg',\n",
       " '../input/train/487.jpg',\n",
       " '../input/train/488.jpg',\n",
       " '../input/train/489.jpg',\n",
       " '../input/train/490.jpg',\n",
       " '../input/train/491.jpg',\n",
       " '../input/train/492.jpg',\n",
       " '../input/train/493.jpg',\n",
       " '../input/train/494.jpg',\n",
       " '../input/train/495.jpg',\n",
       " '../input/train/496.jpg',\n",
       " '../input/train/497.jpg',\n",
       " '../input/train/498.jpg',\n",
       " '../input/train/499.jpg',\n",
       " '../input/train/500.jpg',\n",
       " '../input/train/501.jpg',\n",
       " '../input/train/502.jpg',\n",
       " '../input/train/503.jpg',\n",
       " '../input/train/504.jpg',\n",
       " '../input/train/505.jpg',\n",
       " '../input/train/506.jpg',\n",
       " '../input/train/507.jpg',\n",
       " '../input/train/508.jpg',\n",
       " '../input/train/509.jpg',\n",
       " '../input/train/510.jpg',\n",
       " '../input/train/511.jpg',\n",
       " '../input/train/512.jpg',\n",
       " '../input/train/513.jpg',\n",
       " '../input/train/514.jpg',\n",
       " '../input/train/515.jpg',\n",
       " '../input/train/516.jpg',\n",
       " '../input/train/517.jpg',\n",
       " '../input/train/518.jpg',\n",
       " '../input/train/519.jpg',\n",
       " '../input/train/520.jpg',\n",
       " '../input/train/521.jpg',\n",
       " '../input/train/522.jpg',\n",
       " '../input/train/523.jpg',\n",
       " '../input/train/524.jpg',\n",
       " '../input/train/525.jpg',\n",
       " '../input/train/526.jpg',\n",
       " '../input/train/527.jpg',\n",
       " '../input/train/528.jpg',\n",
       " '../input/train/529.jpg',\n",
       " '../input/train/530.jpg',\n",
       " '../input/train/531.jpg',\n",
       " '../input/train/532.jpg',\n",
       " '../input/train/533.jpg',\n",
       " '../input/train/534.jpg',\n",
       " '../input/train/535.jpg',\n",
       " '../input/train/536.jpg',\n",
       " '../input/train/537.jpg',\n",
       " '../input/train/538.jpg',\n",
       " '../input/train/539.jpg',\n",
       " '../input/train/540.jpg',\n",
       " '../input/train/541.jpg',\n",
       " '../input/train/542.jpg',\n",
       " '../input/train/543.jpg',\n",
       " '../input/train/544.jpg',\n",
       " '../input/train/545.jpg',\n",
       " '../input/train/546.jpg',\n",
       " '../input/train/547.jpg',\n",
       " '../input/train/548.jpg',\n",
       " '../input/train/549.jpg',\n",
       " '../input/train/550.jpg',\n",
       " '../input/train/551.jpg',\n",
       " '../input/train/552.jpg',\n",
       " '../input/train/553.jpg',\n",
       " '../input/train/554.jpg',\n",
       " '../input/train/555.jpg',\n",
       " '../input/train/556.jpg',\n",
       " '../input/train/557.jpg',\n",
       " '../input/train/558.jpg',\n",
       " '../input/train/559.jpg',\n",
       " '../input/train/560.jpg',\n",
       " '../input/train/561.jpg',\n",
       " '../input/train/562.jpg',\n",
       " '../input/train/563.jpg',\n",
       " '../input/train/564.jpg',\n",
       " '../input/train/565.jpg',\n",
       " '../input/train/566.jpg',\n",
       " '../input/train/567.jpg',\n",
       " '../input/train/568.jpg',\n",
       " '../input/train/569.jpg',\n",
       " '../input/train/570.jpg',\n",
       " '../input/train/571.jpg',\n",
       " '../input/train/572.jpg',\n",
       " '../input/train/573.jpg',\n",
       " '../input/train/574.jpg',\n",
       " '../input/train/575.jpg',\n",
       " '../input/train/576.jpg',\n",
       " '../input/train/577.jpg',\n",
       " '../input/train/578.jpg',\n",
       " '../input/train/579.jpg',\n",
       " '../input/train/580.jpg',\n",
       " '../input/train/581.jpg',\n",
       " '../input/train/582.jpg',\n",
       " '../input/train/583.jpg',\n",
       " '../input/train/584.jpg',\n",
       " '../input/train/585.jpg',\n",
       " '../input/train/586.jpg',\n",
       " '../input/train/587.jpg',\n",
       " '../input/train/588.jpg',\n",
       " '../input/train/589.jpg',\n",
       " '../input/train/590.jpg',\n",
       " '../input/train/591.jpg',\n",
       " '../input/train/592.jpg',\n",
       " '../input/train/593.jpg',\n",
       " '../input/train/594.jpg',\n",
       " '../input/train/595.jpg',\n",
       " '../input/train/596.jpg',\n",
       " '../input/train/597.jpg',\n",
       " '../input/train/598.jpg',\n",
       " '../input/train/599.jpg',\n",
       " '../input/train/600.jpg',\n",
       " '../input/train/601.jpg',\n",
       " '../input/train/602.jpg',\n",
       " '../input/train/603.jpg',\n",
       " '../input/train/604.jpg',\n",
       " '../input/train/605.jpg',\n",
       " '../input/train/606.jpg',\n",
       " '../input/train/607.jpg',\n",
       " '../input/train/608.jpg',\n",
       " '../input/train/609.jpg',\n",
       " '../input/train/610.jpg',\n",
       " '../input/train/611.jpg',\n",
       " '../input/train/612.jpg',\n",
       " '../input/train/613.jpg',\n",
       " '../input/train/614.jpg',\n",
       " '../input/train/615.jpg',\n",
       " '../input/train/616.jpg',\n",
       " '../input/train/617.jpg',\n",
       " '../input/train/618.jpg',\n",
       " '../input/train/619.jpg',\n",
       " '../input/train/620.jpg',\n",
       " '../input/train/621.jpg',\n",
       " '../input/train/622.jpg',\n",
       " '../input/train/623.jpg',\n",
       " '../input/train/624.jpg',\n",
       " '../input/train/625.jpg',\n",
       " '../input/train/626.jpg',\n",
       " '../input/train/627.jpg',\n",
       " '../input/train/628.jpg',\n",
       " '../input/train/629.jpg',\n",
       " '../input/train/630.jpg',\n",
       " '../input/train/631.jpg',\n",
       " '../input/train/632.jpg',\n",
       " '../input/train/633.jpg',\n",
       " '../input/train/634.jpg',\n",
       " '../input/train/635.jpg',\n",
       " '../input/train/636.jpg',\n",
       " '../input/train/637.jpg',\n",
       " '../input/train/638.jpg',\n",
       " '../input/train/639.jpg',\n",
       " '../input/train/640.jpg',\n",
       " '../input/train/641.jpg',\n",
       " '../input/train/642.jpg',\n",
       " '../input/train/643.jpg',\n",
       " '../input/train/644.jpg',\n",
       " '../input/train/645.jpg',\n",
       " '../input/train/646.jpg',\n",
       " '../input/train/647.jpg',\n",
       " '../input/train/648.jpg',\n",
       " '../input/train/649.jpg',\n",
       " '../input/train/650.jpg',\n",
       " '../input/train/651.jpg',\n",
       " '../input/train/652.jpg',\n",
       " '../input/train/653.jpg',\n",
       " '../input/train/654.jpg',\n",
       " '../input/train/655.jpg',\n",
       " '../input/train/656.jpg',\n",
       " '../input/train/657.jpg',\n",
       " '../input/train/658.jpg',\n",
       " '../input/train/659.jpg',\n",
       " '../input/train/660.jpg',\n",
       " '../input/train/661.jpg',\n",
       " '../input/train/662.jpg',\n",
       " '../input/train/663.jpg',\n",
       " '../input/train/664.jpg',\n",
       " '../input/train/665.jpg',\n",
       " '../input/train/666.jpg',\n",
       " '../input/train/667.jpg',\n",
       " '../input/train/668.jpg',\n",
       " '../input/train/669.jpg',\n",
       " '../input/train/670.jpg',\n",
       " '../input/train/671.jpg',\n",
       " '../input/train/672.jpg',\n",
       " '../input/train/673.jpg',\n",
       " '../input/train/674.jpg',\n",
       " '../input/train/675.jpg',\n",
       " '../input/train/676.jpg',\n",
       " '../input/train/677.jpg',\n",
       " '../input/train/678.jpg',\n",
       " '../input/train/679.jpg',\n",
       " '../input/train/680.jpg',\n",
       " '../input/train/681.jpg',\n",
       " '../input/train/682.jpg',\n",
       " '../input/train/683.jpg',\n",
       " '../input/train/684.jpg',\n",
       " '../input/train/685.jpg',\n",
       " '../input/train/686.jpg',\n",
       " '../input/train/687.jpg',\n",
       " '../input/train/688.jpg',\n",
       " '../input/train/689.jpg',\n",
       " '../input/train/690.jpg',\n",
       " '../input/train/691.jpg',\n",
       " '../input/train/692.jpg',\n",
       " '../input/train/693.jpg',\n",
       " '../input/train/694.jpg',\n",
       " '../input/train/695.jpg',\n",
       " '../input/train/696.jpg',\n",
       " '../input/train/697.jpg',\n",
       " '../input/train/698.jpg',\n",
       " '../input/train/699.jpg',\n",
       " '../input/train/700.jpg',\n",
       " '../input/train/701.jpg',\n",
       " '../input/train/702.jpg',\n",
       " '../input/train/703.jpg',\n",
       " '../input/train/704.jpg',\n",
       " '../input/train/705.jpg',\n",
       " '../input/train/706.jpg',\n",
       " '../input/train/707.jpg',\n",
       " '../input/train/708.jpg',\n",
       " '../input/train/709.jpg',\n",
       " '../input/train/710.jpg',\n",
       " '../input/train/711.jpg',\n",
       " '../input/train/712.jpg',\n",
       " '../input/train/713.jpg',\n",
       " '../input/train/714.jpg',\n",
       " '../input/train/715.jpg',\n",
       " '../input/train/716.jpg',\n",
       " '../input/train/717.jpg',\n",
       " '../input/train/718.jpg',\n",
       " '../input/train/719.jpg',\n",
       " '../input/train/720.jpg',\n",
       " '../input/train/721.jpg',\n",
       " '../input/train/722.jpg',\n",
       " '../input/train/723.jpg',\n",
       " '../input/train/724.jpg',\n",
       " '../input/train/725.jpg',\n",
       " '../input/train/726.jpg',\n",
       " '../input/train/727.jpg',\n",
       " '../input/train/728.jpg',\n",
       " '../input/train/729.jpg',\n",
       " '../input/train/730.jpg',\n",
       " '../input/train/731.jpg',\n",
       " '../input/train/732.jpg',\n",
       " '../input/train/733.jpg',\n",
       " '../input/train/734.jpg',\n",
       " '../input/train/735.jpg',\n",
       " '../input/train/736.jpg',\n",
       " '../input/train/737.jpg',\n",
       " '../input/train/738.jpg',\n",
       " '../input/train/739.jpg',\n",
       " '../input/train/740.jpg',\n",
       " '../input/train/741.jpg',\n",
       " '../input/train/742.jpg',\n",
       " '../input/train/743.jpg',\n",
       " '../input/train/744.jpg',\n",
       " '../input/train/745.jpg',\n",
       " '../input/train/746.jpg',\n",
       " '../input/train/747.jpg',\n",
       " '../input/train/748.jpg',\n",
       " '../input/train/749.jpg',\n",
       " '../input/train/750.jpg',\n",
       " '../input/train/751.jpg',\n",
       " '../input/train/752.jpg',\n",
       " '../input/train/753.jpg',\n",
       " '../input/train/754.jpg',\n",
       " '../input/train/755.jpg',\n",
       " '../input/train/756.jpg',\n",
       " '../input/train/757.jpg',\n",
       " '../input/train/758.jpg',\n",
       " '../input/train/759.jpg',\n",
       " '../input/train/760.jpg',\n",
       " '../input/train/761.jpg',\n",
       " '../input/train/762.jpg',\n",
       " '../input/train/763.jpg',\n",
       " '../input/train/764.jpg',\n",
       " '../input/train/765.jpg',\n",
       " '../input/train/766.jpg',\n",
       " '../input/train/767.jpg',\n",
       " '../input/train/768.jpg',\n",
       " '../input/train/769.jpg',\n",
       " '../input/train/770.jpg',\n",
       " '../input/train/771.jpg',\n",
       " '../input/train/772.jpg',\n",
       " '../input/train/773.jpg',\n",
       " '../input/train/774.jpg',\n",
       " '../input/train/775.jpg',\n",
       " '../input/train/776.jpg',\n",
       " '../input/train/777.jpg',\n",
       " '../input/train/778.jpg',\n",
       " '../input/train/779.jpg',\n",
       " '../input/train/780.jpg',\n",
       " '../input/train/781.jpg',\n",
       " '../input/train/782.jpg',\n",
       " '../input/train/783.jpg',\n",
       " '../input/train/784.jpg',\n",
       " '../input/train/785.jpg',\n",
       " '../input/train/786.jpg',\n",
       " '../input/train/787.jpg',\n",
       " '../input/train/788.jpg',\n",
       " '../input/train/789.jpg',\n",
       " '../input/train/790.jpg',\n",
       " '../input/train/791.jpg',\n",
       " '../input/train/792.jpg',\n",
       " '../input/train/793.jpg',\n",
       " '../input/train/794.jpg',\n",
       " '../input/train/795.jpg',\n",
       " '../input/train/796.jpg',\n",
       " '../input/train/797.jpg',\n",
       " '../input/train/798.jpg',\n",
       " '../input/train/799.jpg',\n",
       " '../input/train/800.jpg',\n",
       " '../input/train/801.jpg',\n",
       " '../input/train/802.jpg',\n",
       " '../input/train/803.jpg',\n",
       " '../input/train/804.jpg',\n",
       " '../input/train/805.jpg',\n",
       " '../input/train/806.jpg',\n",
       " '../input/train/807.jpg',\n",
       " '../input/train/808.jpg',\n",
       " '../input/train/809.jpg',\n",
       " '../input/train/810.jpg',\n",
       " '../input/train/811.jpg',\n",
       " '../input/train/812.jpg',\n",
       " '../input/train/813.jpg',\n",
       " '../input/train/814.jpg',\n",
       " '../input/train/815.jpg',\n",
       " '../input/train/816.jpg',\n",
       " '../input/train/817.jpg',\n",
       " '../input/train/818.jpg',\n",
       " '../input/train/819.jpg',\n",
       " '../input/train/820.jpg',\n",
       " '../input/train/821.jpg',\n",
       " '../input/train/822.jpg',\n",
       " '../input/train/823.jpg',\n",
       " '../input/train/824.jpg',\n",
       " '../input/train/825.jpg',\n",
       " '../input/train/826.jpg',\n",
       " '../input/train/827.jpg',\n",
       " '../input/train/828.jpg',\n",
       " '../input/train/829.jpg',\n",
       " '../input/train/830.jpg',\n",
       " '../input/train/831.jpg',\n",
       " '../input/train/832.jpg',\n",
       " '../input/train/833.jpg',\n",
       " '../input/train/834.jpg',\n",
       " '../input/train/835.jpg',\n",
       " '../input/train/836.jpg',\n",
       " '../input/train/837.jpg',\n",
       " '../input/train/838.jpg',\n",
       " '../input/train/839.jpg',\n",
       " '../input/train/840.jpg',\n",
       " '../input/train/841.jpg',\n",
       " '../input/train/842.jpg',\n",
       " '../input/train/843.jpg',\n",
       " '../input/train/844.jpg',\n",
       " '../input/train/845.jpg',\n",
       " '../input/train/846.jpg',\n",
       " '../input/train/847.jpg',\n",
       " '../input/train/848.jpg',\n",
       " '../input/train/849.jpg',\n",
       " '../input/train/850.jpg',\n",
       " '../input/train/851.jpg',\n",
       " '../input/train/852.jpg',\n",
       " '../input/train/853.jpg',\n",
       " '../input/train/854.jpg',\n",
       " '../input/train/855.jpg',\n",
       " '../input/train/856.jpg',\n",
       " '../input/train/857.jpg',\n",
       " '../input/train/858.jpg',\n",
       " '../input/train/859.jpg',\n",
       " '../input/train/860.jpg',\n",
       " '../input/train/861.jpg',\n",
       " '../input/train/862.jpg',\n",
       " '../input/train/863.jpg',\n",
       " '../input/train/864.jpg',\n",
       " '../input/train/865.jpg',\n",
       " '../input/train/866.jpg',\n",
       " '../input/train/867.jpg',\n",
       " '../input/train/868.jpg',\n",
       " '../input/train/869.jpg',\n",
       " '../input/train/870.jpg',\n",
       " '../input/train/871.jpg',\n",
       " '../input/train/872.jpg',\n",
       " '../input/train/873.jpg',\n",
       " '../input/train/874.jpg',\n",
       " '../input/train/875.jpg',\n",
       " '../input/train/876.jpg',\n",
       " '../input/train/877.jpg',\n",
       " '../input/train/878.jpg',\n",
       " '../input/train/879.jpg',\n",
       " '../input/train/880.jpg',\n",
       " '../input/train/881.jpg',\n",
       " '../input/train/882.jpg',\n",
       " '../input/train/883.jpg',\n",
       " '../input/train/884.jpg',\n",
       " '../input/train/885.jpg',\n",
       " '../input/train/886.jpg',\n",
       " '../input/train/887.jpg',\n",
       " '../input/train/888.jpg',\n",
       " '../input/train/889.jpg',\n",
       " '../input/train/890.jpg',\n",
       " '../input/train/891.jpg',\n",
       " '../input/train/892.jpg',\n",
       " '../input/train/893.jpg',\n",
       " '../input/train/894.jpg',\n",
       " '../input/train/895.jpg',\n",
       " '../input/train/896.jpg',\n",
       " '../input/train/897.jpg',\n",
       " '../input/train/898.jpg',\n",
       " '../input/train/899.jpg',\n",
       " '../input/train/900.jpg',\n",
       " '../input/train/901.jpg',\n",
       " '../input/train/902.jpg',\n",
       " '../input/train/903.jpg',\n",
       " '../input/train/904.jpg',\n",
       " '../input/train/905.jpg',\n",
       " '../input/train/906.jpg',\n",
       " '../input/train/907.jpg',\n",
       " '../input/train/908.jpg',\n",
       " '../input/train/909.jpg',\n",
       " '../input/train/910.jpg',\n",
       " '../input/train/911.jpg',\n",
       " '../input/train/912.jpg',\n",
       " '../input/train/913.jpg',\n",
       " '../input/train/914.jpg',\n",
       " '../input/train/915.jpg',\n",
       " '../input/train/916.jpg',\n",
       " '../input/train/917.jpg',\n",
       " '../input/train/918.jpg',\n",
       " '../input/train/919.jpg',\n",
       " '../input/train/920.jpg',\n",
       " '../input/train/921.jpg',\n",
       " '../input/train/922.jpg',\n",
       " '../input/train/923.jpg',\n",
       " '../input/train/924.jpg',\n",
       " '../input/train/925.jpg',\n",
       " '../input/train/926.jpg',\n",
       " '../input/train/927.jpg',\n",
       " '../input/train/928.jpg',\n",
       " '../input/train/929.jpg',\n",
       " '../input/train/930.jpg',\n",
       " '../input/train/931.jpg',\n",
       " '../input/train/932.jpg',\n",
       " '../input/train/933.jpg',\n",
       " '../input/train/934.jpg',\n",
       " '../input/train/935.jpg',\n",
       " '../input/train/936.jpg',\n",
       " '../input/train/937.jpg',\n",
       " '../input/train/938.jpg',\n",
       " '../input/train/939.jpg',\n",
       " '../input/train/940.jpg',\n",
       " '../input/train/941.jpg',\n",
       " '../input/train/942.jpg',\n",
       " '../input/train/943.jpg',\n",
       " '../input/train/944.jpg',\n",
       " '../input/train/945.jpg',\n",
       " '../input/train/946.jpg',\n",
       " '../input/train/947.jpg',\n",
       " '../input/train/948.jpg',\n",
       " '../input/train/949.jpg',\n",
       " '../input/train/950.jpg',\n",
       " '../input/train/951.jpg',\n",
       " '../input/train/952.jpg',\n",
       " '../input/train/953.jpg',\n",
       " '../input/train/954.jpg',\n",
       " '../input/train/955.jpg',\n",
       " '../input/train/956.jpg',\n",
       " '../input/train/957.jpg',\n",
       " '../input/train/958.jpg',\n",
       " '../input/train/959.jpg',\n",
       " '../input/train/960.jpg',\n",
       " '../input/train/961.jpg',\n",
       " '../input/train/962.jpg',\n",
       " '../input/train/963.jpg',\n",
       " '../input/train/964.jpg',\n",
       " '../input/train/965.jpg',\n",
       " '../input/train/966.jpg',\n",
       " '../input/train/967.jpg',\n",
       " '../input/train/968.jpg',\n",
       " '../input/train/969.jpg',\n",
       " '../input/train/970.jpg',\n",
       " '../input/train/971.jpg',\n",
       " '../input/train/972.jpg',\n",
       " '../input/train/973.jpg',\n",
       " '../input/train/974.jpg',\n",
       " '../input/train/975.jpg',\n",
       " '../input/train/976.jpg',\n",
       " '../input/train/977.jpg',\n",
       " '../input/train/978.jpg',\n",
       " '../input/train/979.jpg',\n",
       " '../input/train/980.jpg',\n",
       " '../input/train/981.jpg',\n",
       " '../input/train/982.jpg',\n",
       " '../input/train/983.jpg',\n",
       " '../input/train/984.jpg',\n",
       " '../input/train/985.jpg',\n",
       " '../input/train/986.jpg',\n",
       " '../input/train/987.jpg',\n",
       " '../input/train/988.jpg',\n",
       " '../input/train/989.jpg',\n",
       " '../input/train/990.jpg',\n",
       " '../input/train/991.jpg',\n",
       " '../input/train/992.jpg',\n",
       " '../input/train/993.jpg',\n",
       " '../input/train/994.jpg',\n",
       " '../input/train/995.jpg',\n",
       " '../input/train/996.jpg',\n",
       " '../input/train/997.jpg',\n",
       " '../input/train/998.jpg',\n",
       " '../input/train/999.jpg',\n",
       " '../input/train/1000.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['name'] = train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../input/test/\"\n",
    "test_set = pd.read_csv('../input/sample_submission.csv')\n",
    "test_files = []\n",
    "for i in range(len(test_set)):\n",
    "    test_files.append(path + str(int(test_set.iloc[i][0])) +'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 299\n",
    "img_width = 299\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BatchNormalization()(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model(bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_tensor, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "58/57 [==============================] - 94s 2s/step - loss: 0.2691 - acc: 0.8852 - val_loss: 0.1177 - val_acc: 0.9673\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11768, saving model to inception.fold_1.hdf5\n",
      "Epoch 2/50\n",
      "58/57 [==============================] - 61s 1s/step - loss: 0.0872 - acc: 0.9666 - val_loss: 0.0947 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11768 to 0.09472, saving model to inception.fold_1.hdf5\n",
      "Epoch 3/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0555 - acc: 0.9833 - val_loss: 0.0847 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09472 to 0.08472, saving model to inception.fold_1.hdf5\n",
      "Epoch 4/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0323 - acc: 0.9903 - val_loss: 0.1004 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08472\n",
      "Epoch 5/50\n",
      "58/57 [==============================] - 65s 1s/step - loss: 0.0208 - acc: 0.9941 - val_loss: 0.0746 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08472 to 0.07459, saving model to inception.fold_1.hdf5\n",
      "Epoch 6/50\n",
      "58/57 [==============================] - 66s 1s/step - loss: 0.0154 - acc: 0.9957 - val_loss: 0.0789 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07459\n",
      "Epoch 7/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0105 - acc: 0.9984 - val_loss: 0.0667 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07459 to 0.06674, saving model to inception.fold_1.hdf5\n",
      "Epoch 8/50\n",
      "58/57 [==============================] - 65s 1s/step - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0724 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06674\n",
      "Epoch 9/50\n",
      "58/57 [==============================] - 66s 1s/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0645 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06674 to 0.06454, saving model to inception.fold_1.hdf5\n",
      "Epoch 10/50\n",
      "58/57 [==============================] - 65s 1s/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0838 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06454\n",
      "Epoch 11/50\n",
      "58/57 [==============================] - 66s 1s/step - loss: 0.0104 - acc: 0.9989 - val_loss: 0.0855 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.06454\n",
      "Epoch 12/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0728 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.06454\n",
      "Epoch 00012: early stopping\n",
      "48/47 [==============================] - 47s 980ms/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 2\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "58/57 [==============================] - 85s 1s/step - loss: 0.0578 - acc: 0.9808 - val_loss: 0.7264 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.72644, saving model to inception.fold_2.hdf5\n",
      "Epoch 2/50\n",
      "58/57 [==============================] - 60s 1s/step - loss: 0.0316 - acc: 0.9887 - val_loss: 0.0133 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.72644 to 0.01334, saving model to inception.fold_2.hdf5\n",
      "Epoch 3/50\n",
      "58/57 [==============================] - 66s 1s/step - loss: 0.0105 - acc: 0.9984 - val_loss: 0.0224 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01334\n",
      "Epoch 4/50\n",
      "58/57 [==============================] - 63s 1s/step - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0250 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01334\n",
      "Epoch 5/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0090 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01334 to 0.00901, saving model to inception.fold_2.hdf5\n",
      "Epoch 6/50\n",
      "58/57 [==============================] - 66s 1s/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0149 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00901\n",
      "Epoch 7/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0163 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00901\n",
      "Epoch 8/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0032 - acc: 0.9995 - val_loss: 0.0209 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00901\n",
      "Epoch 00008: early stopping\n",
      "48/47 [==============================] - 45s 940ms/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 3\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "58/57 [==============================] - 89s 2s/step - loss: 0.0401 - acc: 0.9898 - val_loss: 0.1695 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.16953, saving model to inception.fold_3.hdf5\n",
      "Epoch 2/50\n",
      "58/57 [==============================] - 61s 1s/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0176 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.16953 to 0.01758, saving model to inception.fold_3.hdf5\n",
      "Epoch 3/50\n",
      "58/57 [==============================] - 68s 1s/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0132 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01758 to 0.01324, saving model to inception.fold_3.hdf5\n",
      "Epoch 4/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0117 - acc: 0.9957 - val_loss: 0.0100 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01324 to 0.01002, saving model to inception.fold_3.hdf5\n",
      "Epoch 5/50\n",
      "58/57 [==============================] - 68s 1s/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0638 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.01002\n",
      "Epoch 6/50\n",
      "58/57 [==============================] - 63s 1s/step - loss: 0.0081 - acc: 0.9984 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01002 to 0.00508, saving model to inception.fold_3.hdf5\n",
      "Epoch 7/50\n",
      "58/57 [==============================] - 66s 1s/step - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0086 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00508\n",
      "Epoch 8/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00508\n",
      "Epoch 9/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0446 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00508\n",
      "Epoch 00009: early stopping\n",
      "48/47 [==============================] - 48s 1s/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 4\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "58/57 [==============================] - 95s 2s/step - loss: 0.0215 - acc: 0.9903 - val_loss: 0.4507 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45066, saving model to inception.fold_4.hdf5\n",
      "Epoch 2/50\n",
      "58/57 [==============================] - 64s 1s/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0479 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45066 to 0.04791, saving model to inception.fold_4.hdf5\n",
      "Epoch 3/50\n",
      "58/57 [==============================] - 71s 1s/step - loss: 0.0089 - acc: 0.9951 - val_loss: 0.0488 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04791\n",
      "Epoch 4/50\n",
      "58/57 [==============================] - 67s 1s/step - loss: 0.0059 - acc: 0.9978 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04791 to 0.00518, saving model to inception.fold_4.hdf5\n",
      "Epoch 5/50\n",
      "58/57 [==============================] - 72s 1s/step - loss: 0.0057 - acc: 0.9978 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00518 to 0.00201, saving model to inception.fold_4.hdf5\n",
      "Epoch 6/50\n",
      "58/57 [==============================] - 72s 1s/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0075 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00201\n",
      "Epoch 7/50\n",
      "58/57 [==============================] - 72s 1s/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00201 to 0.00195, saving model to inception.fold_4.hdf5\n",
      "Epoch 8/50\n",
      "58/57 [==============================] - 72s 1s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00195\n",
      "Epoch 00008: early stopping\n",
      "48/47 [==============================] - 50s 1s/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 5\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "58/57 [==============================] - 99s 2s/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.0575 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05750, saving model to inception.fold_5.hdf5\n",
      "Epoch 2/50\n",
      "58/57 [==============================] - 63s 1s/step - loss: 0.0247 - acc: 0.9935 - val_loss: 0.0154 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05750 to 0.01540, saving model to inception.fold_5.hdf5\n",
      "Epoch 3/50\n",
      "58/57 [==============================] - 71s 1s/step - loss: 0.0162 - acc: 0.9957 - val_loss: 0.0066 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01540 to 0.00656, saving model to inception.fold_5.hdf5\n",
      "Epoch 4/50\n",
      "58/57 [==============================] - 70s 1s/step - loss: 0.0193 - acc: 0.9951 - val_loss: 0.0317 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00656\n",
      "Epoch 5/50\n",
      "58/57 [==============================] - 65s 1s/step - loss: 0.0073 - acc: 0.9984 - val_loss: 0.0183 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00656\n",
      "Epoch 6/50\n",
      "58/57 [==============================] - 71s 1s/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00656 to 0.00567, saving model to inception.fold_5.hdf5\n",
      "Epoch 7/50\n",
      "58/57 [==============================] - 71s 1s/step - loss: 0.0052 - acc: 0.9978 - val_loss: 0.0080 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00567\n",
      "Epoch 8/50\n",
      "58/57 [==============================] - 71s 1s/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0198 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00567\n",
      "Epoch 9/50\n",
      "58/57 [==============================] - 71s 1s/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0124 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00567\n",
      "Epoch 00009: early stopping\n",
      "48/47 [==============================] - 49s 1s/step\n",
      "\n",
      "\n",
      "\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n",
    "\n",
    "    preds_test = np.zeros(len(test), dtype = np.float)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x.iloc[train_index]\n",
    "        x_valid = x.iloc[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_valid = y[test_index]\n",
    "\n",
    "        def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "\n",
    "        def train_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_train), batch_size):\n",
    "                    x_batch = []\n",
    "                    y_batch = []\n",
    "                    end = min(start + batch_size, len(x_train))\n",
    "                    train_batch = x_train[start:end]\n",
    "                    for filepath, tag in train_batch.values:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        img = augment(img, np.random.randint(6))\n",
    "                        x_batch.append(img)\n",
    "                        y_batch.append(tag)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def valid_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_valid), batch_size):\n",
    "                    x_batch = []\n",
    "                    y_batch = []\n",
    "                    end = min(start + batch_size, len(x_valid))\n",
    "                    valid_batch = x_valid[start:end]\n",
    "                    for filepath, tag in valid_batch.values:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        img = augment(img, np.random.randint(6))\n",
    "                        x_batch.append(img)\n",
    "                        y_batch.append(tag)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def test_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(test), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(test))\n",
    "                    test_batch = test[start:end]\n",
    "                    for filepath in test_batch:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    yield x_batch\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                             save_best_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "        test_steps = len(test) / batch_size\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n",
    "                            callbacks=callbacks, validation_data=valid_generator(), \n",
    "                            validation_steps=valid_steps)\n",
    "        \n",
    "        filepath='inception.fold_' + str(i) + '.hdf5'\n",
    "        model.load_weights(filepath)\n",
    "\n",
    "        \n",
    "        preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "                                              steps=test_steps, verbose=1)[:, -1]\n",
    "\n",
    "        preds_test += preds_test_fold\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "\n",
    "\n",
    "    return preds_test\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50 \n",
    "n_fold = 5\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "test_pred = train_model(model, batch_size, epochs, img_size, train_set, \n",
    "                        train_label, test_files, n_fold, kf)\n",
    "\n",
    "test_set['invasive'] = test_pred\n",
    "test_set.to_csv('fold5_batch32.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
