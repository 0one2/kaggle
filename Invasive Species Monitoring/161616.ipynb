{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "368/367 [==============================] - 205s 556ms/step - loss: 0.2470 - acc: 0.9038 - val_loss: 0.0662 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06617, saving model to inception.fold_1.hdf5\n",
      "Epoch 2/50\n",
      "368/367 [==============================] - 174s 472ms/step - loss: 0.1191 - acc: 0.9609 - val_loss: 0.0810 - val_acc: 0.9608\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06617\n",
      "Epoch 3/50\n",
      "368/367 [==============================] - 174s 472ms/step - loss: 0.0666 - acc: 0.9788 - val_loss: 0.0399 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06617 to 0.03991, saving model to inception.fold_1.hdf5\n",
      "Epoch 4/50\n",
      "368/367 [==============================] - 173s 470ms/step - loss: 0.0422 - acc: 0.9902 - val_loss: 0.0307 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03991 to 0.03073, saving model to inception.fold_1.hdf5\n",
      "Epoch 5/50\n",
      "368/367 [==============================] - 173s 471ms/step - loss: 0.0324 - acc: 0.9935 - val_loss: 0.0302 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03073 to 0.03018, saving model to inception.fold_1.hdf5\n",
      "Epoch 6/50\n",
      "368/367 [==============================] - 174s 473ms/step - loss: 0.0260 - acc: 0.9951 - val_loss: 0.0306 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03018\n",
      "Epoch 7/50\n",
      "368/367 [==============================] - 174s 474ms/step - loss: 0.0235 - acc: 0.9924 - val_loss: 0.0210 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03018 to 0.02097, saving model to inception.fold_1.hdf5\n",
      "Epoch 8/50\n",
      "368/367 [==============================] - 174s 474ms/step - loss: 0.0166 - acc: 0.9957 - val_loss: 0.0194 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02097 to 0.01942, saving model to inception.fold_1.hdf5\n",
      "Epoch 9/50\n",
      "368/367 [==============================] - 173s 470ms/step - loss: 0.0194 - acc: 0.9935 - val_loss: 0.0180 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01942 to 0.01796, saving model to inception.fold_1.hdf5\n",
      "Epoch 10/50\n",
      "368/367 [==============================] - 173s 471ms/step - loss: 0.0154 - acc: 0.9978 - val_loss: 0.0195 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01796\n",
      "Epoch 11/50\n",
      "368/367 [==============================] - 173s 471ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0309 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01796\n",
      "Epoch 12/50\n",
      "368/367 [==============================] - 175s 474ms/step - loss: 0.0171 - acc: 0.9957 - val_loss: 0.0173 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01796 to 0.01729, saving model to inception.fold_1.hdf5\n",
      "Epoch 13/50\n",
      "368/367 [==============================] - 174s 473ms/step - loss: 0.0141 - acc: 0.9962 - val_loss: 0.0216 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01729\n",
      "Epoch 14/50\n",
      "368/367 [==============================] - 173s 471ms/step - loss: 0.0159 - acc: 0.9957 - val_loss: 0.0202 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01729\n",
      "Epoch 15/50\n",
      "368/367 [==============================] - 174s 472ms/step - loss: 0.0159 - acc: 0.9951 - val_loss: 0.0182 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01729\n",
      "Epoch 00015: early stopping\n",
      "307/306 [==============================] - 72s 234ms/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 2\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "117/367 [========>.....................] - ETA: 2:27 - loss: 0.1041 - acc: 0.9709"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "path = \"../input/train/\"\n",
    "train_set = pd.read_csv('../input/train_labels.csv')\n",
    "train_label = np.array(train_set['invasive'])\n",
    "train_files = []\n",
    "for i in range(len(train_set)):\n",
    "    train_files.append(path + str(int(train_set.iloc[i][0])) +'.jpg')\n",
    "train_set['name'] = train_files\n",
    "path = \"../input/test/\"\n",
    "test_set = pd.read_csv('../input/sample_submission.csv')\n",
    "test_files = []\n",
    "for i in range(len(test_set)):\n",
    "    test_files.append(path + str(int(test_set.iloc[i][0])) +'.jpg')\n",
    "img_height = 800\n",
    "img_width = 800\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=img_dim)\n",
    "\n",
    "input_tensor = Input(shape=img_dim)\n",
    "bn = BatchNormalization()(input_tensor)\n",
    "x = base_model(bn)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, output)\n",
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n",
    "\n",
    "    preds_train = np.zeros(len(x), dtype = np.float)\n",
    "    preds_test = np.zeros(len(test), dtype = np.float)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x.iloc[train_index]\n",
    "        x_valid = x.iloc[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_valid = y[test_index]\n",
    "\n",
    "        def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "\n",
    "        def train_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_train), batch_size):\n",
    "                    x_batch = []\n",
    "                    y_batch = []\n",
    "                    end = min(start + batch_size, len(x_train))\n",
    "                    train_batch = x_train[start:end]\n",
    "                    for filepath, tag in train_batch.values:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        img = augment(img, np.random.randint(6))\n",
    "                        x_batch.append(img)\n",
    "                        y_batch.append(tag)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def valid_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_valid), batch_size):\n",
    "                    x_batch = []\n",
    "                    y_batch = []\n",
    "                    end = min(start + batch_size, len(x_valid))\n",
    "                    valid_batch = x_valid[start:end]\n",
    "                    for filepath, tag in valid_batch.values:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        img = augment(img, np.random.randint(6))\n",
    "                        x_batch.append(img)\n",
    "                        y_batch.append(tag)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def test_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(test), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(test))\n",
    "                    test_batch = test[start:end]\n",
    "                    for filepath in test_batch:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    yield x_batch\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                             save_best_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "        test_steps = len(test) / batch_size\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n",
    "                            callbacks=callbacks, validation_data=valid_generator(), \n",
    "                            validation_steps=valid_steps)\n",
    "        \n",
    "        filepath='inception.fold_' + str(i) + '.hdf5'\n",
    "        model.load_weights(filepath)\n",
    "\n",
    "        \n",
    "        preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "                                              steps=test_steps, verbose=1)[:, -1]\n",
    "\n",
    "        preds_test += preds_test_fold\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "\n",
    "\n",
    "    return preds_test\n",
    "\n",
    "batch_size = 5\n",
    "epochs = 50 \n",
    "n_fold = 5\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True, random_state=16)\n",
    "\n",
    "test_pred = train_model(model, batch_size, epochs, img_size, train_set, \n",
    "                        train_label, test_files, n_fold, kf)\n",
    "\n",
    "test_set['invasive'] = test_pred\n",
    "test_set.to_csv('fold5_batch5.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
