{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "368/367 [==============================] - 200s 545ms/step - loss: 0.2547 - acc: 0.9005 - val_loss: 0.0896 - val_acc: 0.9673\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08960, saving model to inception.fold_1.hdf5\n",
      "Epoch 2/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.1339 - acc: 0.9592 - val_loss: 0.1396 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.08960\n",
      "Epoch 3/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.0750 - acc: 0.9810 - val_loss: 0.0647 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08960 to 0.06469, saving model to inception.fold_1.hdf5\n",
      "Epoch 4/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.0539 - acc: 0.9886 - val_loss: 0.0613 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06469 to 0.06128, saving model to inception.fold_1.hdf5\n",
      "Epoch 5/50\n",
      "368/367 [==============================] - 172s 469ms/step - loss: 0.0493 - acc: 0.9853 - val_loss: 0.0607 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06128 to 0.06072, saving model to inception.fold_1.hdf5\n",
      "Epoch 6/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.0323 - acc: 0.9951 - val_loss: 0.0411 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06072 to 0.04112, saving model to inception.fold_1.hdf5\n",
      "Epoch 7/50\n",
      "368/367 [==============================] - 172s 466ms/step - loss: 0.0284 - acc: 0.9935 - val_loss: 0.0478 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04112\n",
      "Epoch 8/50\n",
      "368/367 [==============================] - 172s 466ms/step - loss: 0.0214 - acc: 0.9973 - val_loss: 0.0422 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04112\n",
      "Epoch 9/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.0214 - acc: 0.9962 - val_loss: 0.0350 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04112 to 0.03499, saving model to inception.fold_1.hdf5\n",
      "Epoch 10/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.0259 - acc: 0.9951 - val_loss: 0.0481 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03499\n",
      "Epoch 11/50\n",
      "368/367 [==============================] - 172s 468ms/step - loss: 0.0206 - acc: 0.9978 - val_loss: 0.0294 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03499 to 0.02941, saving model to inception.fold_1.hdf5\n",
      "Epoch 12/50\n",
      "368/367 [==============================] - 172s 467ms/step - loss: 0.0222 - acc: 0.9962 - val_loss: 0.0408 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02941\n",
      "Epoch 13/50\n",
      "368/367 [==============================] - 172s 468ms/step - loss: 0.0203 - acc: 0.9978 - val_loss: 0.0310 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02941\n",
      "Epoch 14/50\n",
      "368/367 [==============================] - 172s 468ms/step - loss: 0.0206 - acc: 0.9978 - val_loss: 0.0466 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02941\n",
      "Epoch 00014: early stopping\n",
      "307/306 [==============================] - 78s 255ms/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 2\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "368/367 [==============================] - 187s 509ms/step - loss: 0.1200 - acc: 0.9609 - val_loss: 0.1024 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10236, saving model to inception.fold_2.hdf5\n",
      "Epoch 2/50\n",
      "113/367 [========>.....................] - ETA: 1:39 - loss: 0.0683 - acc: 0.9752"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "path = \"../input/train/\"\n",
    "train_set = pd.read_csv('../input/train_labels.csv')\n",
    "train_label = np.array(train_set['invasive'])\n",
    "train_files = []\n",
    "for i in range(len(train_set)):\n",
    "    train_files.append(path + str(int(train_set.iloc[i][0])) +'.jpg')\n",
    "train_set['name'] = train_files\n",
    "path = \"../input/test/\"\n",
    "test_set = pd.read_csv('../input/sample_submission.csv')\n",
    "test_files = []\n",
    "for i in range(len(test_set)):\n",
    "    test_files.append(path + str(int(test_set.iloc[i][0])) +'.jpg')\n",
    "img_height = 800\n",
    "img_width = 800\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=img_dim)\n",
    "\n",
    "input_tensor = Input(shape=img_dim)\n",
    "bn = BatchNormalization()(input_tensor)\n",
    "x = base_model(bn)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, output)\n",
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n",
    "\n",
    "    preds_train = np.zeros(len(x), dtype = np.float)\n",
    "    preds_test = np.zeros(len(test), dtype = np.float)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x.iloc[train_index]\n",
    "        x_valid = x.iloc[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_valid = y[test_index]\n",
    "\n",
    "        def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "\n",
    "        def train_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_train), batch_size):\n",
    "                    x_batch = []\n",
    "                    y_batch = []\n",
    "                    end = min(start + batch_size, len(x_train))\n",
    "                    train_batch = x_train[start:end]\n",
    "                    for filepath, tag in train_batch.values:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        img = augment(img, np.random.randint(6))\n",
    "                        x_batch.append(img)\n",
    "                        y_batch.append(tag)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def valid_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_valid), batch_size):\n",
    "                    x_batch = []\n",
    "                    y_batch = []\n",
    "                    end = min(start + batch_size, len(x_valid))\n",
    "                    valid_batch = x_valid[start:end]\n",
    "                    for filepath, tag in valid_batch.values:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        img = augment(img, np.random.randint(6))\n",
    "                        x_batch.append(img)\n",
    "                        y_batch.append(tag)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def test_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(test), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(test))\n",
    "                    test_batch = test[start:end]\n",
    "                    for filepath in test_batch:\n",
    "                        img = cv2.imread(filepath)\n",
    "                        img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    yield x_batch\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                             save_best_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "        test_steps = len(test) / batch_size\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', \n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n",
    "                            callbacks=callbacks, validation_data=valid_generator(), \n",
    "                            validation_steps=valid_steps)\n",
    "        \n",
    "        filepath='inception.fold_' + str(i) + '.hdf5'\n",
    "        model.load_weights(filepath)\n",
    "\n",
    "        \n",
    "        preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "                                              steps=test_steps, verbose=1)[:, -1]\n",
    "\n",
    "        preds_test += preds_test_fold\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "\n",
    "\n",
    "    return preds_test\n",
    "\n",
    "batch_size = 5\n",
    "epochs = 50 \n",
    "n_fold = 5\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "test_pred = train_model(model, batch_size, epochs, img_size, train_set, \n",
    "                        train_label, test_files, n_fold, kf)\n",
    "\n",
    "test_set['invasive'] = test_pred\n",
    "test_set.to_csv('fold5_batch5.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
